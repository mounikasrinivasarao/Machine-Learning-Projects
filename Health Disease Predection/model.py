# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bcT9XiREl19QTEClT0ztAg0CRKe8uU4Z
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# ML libraries for data processing
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split

import warnings
# Suppress all warnings
warnings.filterwarnings("ignore")

# Display the path of the file
import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

from google.colab import files
uploades = files.upload()

data = pd.read_csv('/content/heart.csv')

data.head()

data.tail()

data.info()

data.describe()

data.shape

# Set the figure size
plt.figure(figsize=(10, 6))

# Create a histogram using Seaborn
sns.histplot(data['age'], kde=True)

# Add title and labels
plt.title('Histogram of Age')
plt.xlabel('Age')
plt.ylabel('Number of Patients')

# Show the plot
plt.show()

# Set the figure size
plt.figure(figsize=(10, 6))

# Create a histogram using Seaborn
sns.histplot(data['chol'], kde=True)

# Add title and labels
plt.title('Distribution of Cholesterol Level')
plt.xlabel('Cholesterol Level')
plt.ylabel('Number of Patients')

# Show the plot
plt.show()

# Set the figure size
plt.figure(figsize=(8, 6))

# Create a countplot using Seaborn
sns.countplot(x='sex', data=data, hue='target')

# Add title and labels
plt.title('Presence of Heart Disease by Gender')
plt.xlabel('Gender (0: Female, 1: Male)')
plt.ylabel('Number of Patients')
plt.legend(['No Disease', 'Heart Disease'])

# Show the plot
plt.show()

# Set the figure size
plt.figure(figsize=(12, 8))

# Create a heatmap using Seaborn
sns.heatmap(data.corr(), annot=True, cmap='coolwarm', fmt='.2f')

# Add title
plt.title('Correlation Matrix')

# Show the plot
plt.show()

# Set the figure size
plt.figure(figsize=(8, 6))

# Create a scatter plot using Seaborn
sns.scatterplot(x='age', y='chol', data=data)

# Add title and labels
plt.title('Scatter Plot: Age vs Cholesterol Level')
plt.xlabel('Age')
plt.ylabel('Cholesterol Level')

# Show the plot
plt.show()

# Create a pair plot using Seaborn
sns.pairplot(data[['age', 'chol', 'thalach', 'trestbps']])

# Add a title
plt.suptitle('Pair Plot of Variables')

# Show the plot
plt.show()

sns.pairplot(data)

# Set the figure size
plt.figure(figsize=(12, 8))

# Create boxplots using Seaborn
sns.boxplot(data=data[['age', 'chol', 'thalach', 'trestbps']])

# Add title and labels
plt.title('Boxplots of Variables')
plt.xlabel('Variables')
plt.ylabel('Values')

# Show the plot
plt.show()

sns.boxplot(data=data)

for col in data.columns:
    q1 = data[col].quantile(0.25)
    q3 = data[col].quantile(0.75)
    iqr = q3 - q1
    lower_bound = q1 - 1.5 * iqr
    upper_bound = q3 + 1.5 * iqr
    data[col] = np.where((data[col] < lower_bound) | (data[col] > upper_bound), data[col].mean(), data[col])

plt.figure(figsize=(12, 8))

# Create boxplots using Seaborn
sns.boxplot(data=data[['age', 'chol', 'thalach', 'trestbps']])

# Add title and labels
plt.title('Boxplots of Variables')
plt.xlabel('Variables')
plt.ylabel('Values')

# Show the plot
plt.show()

# selects columns with data types 'object', which typically represents categorical variables.
# The tolist() method converts the column names to a list
categorical_cols = data.select_dtypes(include=['object']).columns.tolist()

#  selects columns with data types 'int' and 'float', which represent numerical variables.
numerical_cols = data.select_dtypes(include=['int', 'float']).columns.tolist()

# print the list of categorical column names.
print("Categorical column:", categorical_cols)

#  print the list of numerical column names.
print("Numerical column:", numerical_cols)

categorical_cols = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']
numerical_cols = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']

df_processed = data.copy()

scaler = StandardScaler()
df_processed[numerical_cols] = scaler.fit_transform(df_processed[numerical_cols])

label_encoder = LabelEncoder()
df_processed[categorical_cols] = df_processed[categorical_cols].apply(lambda col: label_encoder.fit_transform(col))

features = df_processed.drop('target', axis=1)
target = df_processed['target']

X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)

# X_train.shape, X_test.shape, y_train.shape, y_test.shape
print(f'The shape of training features is: {X_train.shape}')
print(f'The shape of training target is: {y_train.shape}')

print(f'The shape of testing features is: {X_test.shape}')
print(f'The shape of testing target is: {y_test.shape}')

from sklearn.neighbors import KNeighborsClassifier

# Instantiation of the 5-NN classifier
knn = KNeighborsClassifier(n_neighbors=5)

# Training the classifier on the training data
knn.fit(X_train, y_train)

# Prediction on the test data
y_pred = knn.predict(X_test)
print("y_pred",y_pred[0])

print(len(y_pred),y_pred[:6])

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Calculation of accuracy
accuracy = accuracy_score(y_test, y_pred)

# Calculation of precision
precision = precision_score(y_test, y_pred)

# Calculation of recall
recall = recall_score(y_test, y_pred)

# Calculation of F1 score
f1 = f1_score(y_test, y_pred)

# Displaying the results
print("Accuracy: {:.2f}%".format(accuracy * 100))
print("Precision: {:.2f}%".format(precision * 100))
print("Recall: {:.2f}%".format(recall * 100))
print("F1 Score: {:.2f}%".format(f1 * 100))

results = []

# Testing different values of k from 1 to 10
for k in range(1, 11):
    # Instantiation of the k-NN classifier
    knn = KNeighborsClassifier(n_neighbors=k)

    # Training the classifier on the training data
    knn.fit(X_train, y_train)

    # Prediction on the test data
    y_pred = knn.predict(X_test)

    # Calculation of accuracy
    accuracy = accuracy_score(y_test, y_pred)

    # Adding results to the list
    results.append((k, accuracy))

# Creating a DataFrame to display the results
results_df = pd.DataFrame(results, columns=['k', 'Accuracy'])
print(results_df)

plt.figure(figsize=(10, 6))
plt.plot(results_df['k'], results_df['Accuracy'], marker='o', linestyle='-', color='b')
plt.title('Accuracy vs. k Value')
plt.xlabel('k (Number of Neighbors)')
plt.ylabel('Accuracy')
plt.grid(True)
plt.show()

# After data preprocessing (scaling and encoding)
import pickle

# Save the preprocessed features (X_train, X_test) and target variables (y_train, y_test)
with open('preprocessed_data.pkl', 'wb') as f:
    pickle.dump((X_train, X_test, y_train, y_test), f)

# After training and hyperparameter tuning (finding the best k value)
# Assuming knn is the trained KNeighborsClassifier model

with open('knn_model.pkl', 'wb') as f:
    pickle.dump(knn, f)

